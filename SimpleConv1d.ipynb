{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1Von9iPi5vPYRYwB0g6ri",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aderibigbeolamide/Assignment_Machine_Learning/blob/main/SimpleConv1d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TtF4hUQneXbc"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 1"
      ],
      "metadata": {
        "id": "8pRblRUlnTVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleConv1d:\n",
        "    def __init__(self, filter_size, initializer, optimizer, stride=1):\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(1, filter_size)\n",
        "        self.B = initializer.B(1)\n",
        "        self.grads = {}\n",
        "        self.X = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        output_size = (len(X) - self.filter_size) // self.stride + 1\n",
        "        out = np.zeros(output_size)\n",
        "\n",
        "        for i in range(output_size):\n",
        "            out[i] = np.sum(X[i*self.stride:i*self.stride + self.filter_size] * self.W) + self.B\n",
        "        return out\n",
        "\n",
        "    def backward(self, dA):\n",
        "        dW = np.zeros_like(self.W)\n",
        "        dB = np.sum(dA)\n",
        "        dX = np.zeros_like(self.X)\n",
        "        output_size = (len(self.X) - self.filter_size) // self.stride + 1\n",
        "\n",
        "        for i in range(output_size):\n",
        "            dW += dA[i] * self.X[i*self.stride:i*self.stride + self.filter_size]\n",
        "            dX[i*self.stride:i*self.stride + self.filter_size] += dA[i] * self.W\n",
        "\n",
        "        self.grads['W'] = dW\n",
        "        self.grads['B'] = dB\n",
        "        self.optimizer.update(self)\n",
        "        return dX\n",
        "\n",
        "class XavierInitializer:\n",
        "    def W(self, input_dim, output_dim):\n",
        "        return np.random.randn(input_dim, output_dim) * np.sqrt(1 / input_dim)\n",
        "\n",
        "    def B(self, output_dim):\n",
        "        return np.zeros(output_dim)\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.h = None\n",
        "\n",
        "    def update(self, layer):\n",
        "        if self.h is None:\n",
        "            self.h = {}\n",
        "            for key, value in layer.grads.items():\n",
        "                self.h[key] = np.zeros_like(value)\n",
        "\n",
        "        for key in layer.grads.keys():\n",
        "            self.h[key] += layer.grads[key] * layer.grads[key]\n",
        "            layer.W -= self.lr * layer.grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n",
        "\n",
        "            if key == 'B':\n",
        "                layer.B -= self.lr * layer.grads[key] / (np.sqrt(self.h[key]) + 1e-7)\n"
      ],
      "metadata": {
        "id": "ejr4vQY9epTz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 2"
      ],
      "metadata": {
        "id": "QxrmyQjxospj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleConv1d:\n",
        "    def __init__(self, filter_size, initializer, optimizer, stride=1, padding=0):\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(1, filter_size)\n",
        "        self.B = initializer.B(1)\n",
        "        self.grads = {}\n",
        "        self.X = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = np.pad(X, (self.padding, self.padding), 'constant')\n",
        "        output_size = self.calculate_output_size(len(self.X), self.padding, self.filter_size, self.stride)\n",
        "        out = np.zeros(output_size)\n",
        "\n",
        "        for i in range(output_size):\n",
        "            out[i] = np.sum(self.X[i*self.stride:i*self.stride + self.filter_size] * self.W) + self.B\n",
        "        return out\n",
        "\n",
        "    def backward(self, dA):\n",
        "        dW = np.zeros_like(self.W)\n",
        "        dB = np.sum(dA)\n",
        "        dX = np.zeros_like(self.X)\n",
        "        output_size = self.calculate_output_size(len(self.X), self.padding, self.filter_size, self.stride)\n",
        "\n",
        "        for i in range(output_size):\n",
        "            dW += dA[i] * self.X[i*self.stride:i*self.stride + self.filter_size]\n",
        "            dX[i*self.stride:i*self.stride + self.filter_size] += dA[i] * self.W\n",
        "\n",
        "        self.grads['W'] = dW\n",
        "        self.grads['B'] = dB\n",
        "        self.optimizer.update(self)\n",
        "        return dX\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_output_size(N_in, P, F, S):\n",
        "        \"\"\"\n",
        "        Calculate the output size after a 1D convolution.\n",
        "\n",
        "        Parameters:\n",
        "        N_in (int): Size of the input (number of features).\n",
        "        P (int): Number of paddings in a direction.\n",
        "        F (int): Filter size.\n",
        "        S (int): Size of stride.\n",
        "\n",
        "        Returns:\n",
        "        int: Size of the output (number of features).\n",
        "        \"\"\"\n",
        "        return (N_in + 2 * P - F) // S + 1\n"
      ],
      "metadata": {
        "id": "-3c-ZEtFnabU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 3"
      ],
      "metadata": {
        "id": "IIHSSH3I40sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleConv1d:\n",
        "    def __init__(self, filter_size, stride=1, padding=0):\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.W = None\n",
        "        self.B = None\n",
        "        self.X = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = np.pad(X, (self.padding, self.padding), 'constant')\n",
        "        output_size = self.calculate_output_size(len(self.X), self.padding, self.filter_size, self.stride)\n",
        "        out = np.zeros(output_size)\n",
        "\n",
        "        for i in range(output_size):\n",
        "            out[i] = np.sum(self.X[i*self.stride:i*self.stride + self.filter_size] * self.W) + self.B\n",
        "        return out\n",
        "\n",
        "    def backward(self, dA):\n",
        "        dW = np.zeros_like(self.W)\n",
        "        dB = np.sum(dA)\n",
        "        dX = np.zeros_like(self.X)\n",
        "        output_size = self.calculate_output_size(len(self.X), self.padding, self.filter_size, self.stride)\n",
        "\n",
        "        for i in range(output_size):\n",
        "            dW += dA[i] * self.X[i*self.stride:i*self.stride + self.filter_size]\n",
        "            dX[i*self.stride:i*self.stride + self.filter_size] += dA[i] * self.W\n",
        "\n",
        "        dX = dX[self.padding:len(dX) - self.padding]\n",
        "        return dW, dB, dX\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_output_size(N_in, P, F, S):\n",
        "        return (N_in + 2 * P - F) // S + 1\n",
        "\n",
        "\n",
        "X = np.array([1, 2, 3, 4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = 1\n",
        "\n",
        "\n",
        "conv1d = SimpleConv1d(filter_size=len(w))\n",
        "conv1d.W = w\n",
        "conv1d.B = b\n",
        "\n",
        "\n",
        "out = conv1d.forward(X)\n",
        "print(\"Forward output:\", out)\n",
        "\n",
        "\n",
        "delta_a = np.array([10, 20])\n",
        "dW, dB, dX = conv1d.backward(delta_a)\n",
        "print(\"Backward dB:\", dB)\n",
        "print(\"Backward dW:\", dW)\n",
        "print(\"Backward dX:\", dX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYmMqTu3oygo",
        "outputId": "96485c41-9a88-40a8-ceaf-f3d66d85d058"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward output: [35. 50.]\n",
            "Backward dB: 30\n",
            "Backward dW: [ 50  80 110]\n",
            "Backward dX: [ 30 110 170 140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Problem 4"
      ],
      "metadata": {
        "id": "UKa2oEEnPhQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1d:\n",
        "    def __init__(self, num_input_channels, num_output_channels, filter_size, stride=1, padding=0):\n",
        "        self.num_input_channels = num_input_channels\n",
        "        self.num_output_channels = num_output_channels\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "\n",
        "\n",
        "        self.W = np.random.randn(num_output_channels, num_input_channels, filter_size) * np.sqrt(2 / (num_input_channels * filter_size))\n",
        "        self.B = np.zeros(num_output_channels)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.X = np.pad(X, ((0, 0), (self.padding, self.padding)), 'constant').astype(float)\n",
        "        num_features = self.X.shape[1]\n",
        "        output_size = self.calculate_output_size(num_features, self.padding, self.filter_size, self.stride)\n",
        "        out = np.zeros((self.num_output_channels, output_size))\n",
        "\n",
        "\n",
        "        for out_channel in range(self.num_output_channels):\n",
        "            for i in range(output_size):\n",
        "                out[out_channel, i] = np.sum(\n",
        "                    self.X[:, i*self.stride:i*self.stride + self.filter_size] * self.W[out_channel, :, :]\n",
        "                ) + self.B[out_channel]\n",
        "        return out\n",
        "\n",
        "    def backward(self, dA):\n",
        "        dW = np.zeros_like(self.W)\n",
        "        dB = np.zeros_like(self.B)\n",
        "        dX = np.zeros_like(self.X, dtype=float)\n",
        "\n",
        "        output_size = dA.shape[1]\n",
        "\n",
        "        for out_channel in range(self.num_output_channels):\n",
        "            dB[out_channel] = np.sum(dA[out_channel])\n",
        "            for i in range(output_size):\n",
        "                dW[out_channel, :, :] += dA[out_channel, i] * self.X[:, i*self.stride:i*self.stride + self.filter_size]\n",
        "                dX[:, i*self.stride:i*self.stride + self.filter_size] += dA[out_channel, i] * self.W[out_channel, :, :]\n",
        "\n",
        "        if self.padding != 0:\n",
        "            dX = dX[:, self.padding:-self.padding]\n",
        "        return dW, dB, dX\n",
        "\n",
        "    @staticmethod\n",
        "    def calculate_output_size(N_in, P, F, S):\n",
        "        return (N_in + 2 * P - F) // S + 1\n",
        "\n",
        "\n",
        "X = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])\n",
        "w = np.ones((3, 2, 3))\n",
        "b = np.array([1, 2, 3])\n",
        "\n",
        "\n",
        "conv1d = Conv1d(num_input_channels=2, num_output_channels=3, filter_size=3)\n",
        "conv1d.W = w\n",
        "conv1d.B = b\n",
        "\n",
        "\n",
        "out = conv1d.forward(X)\n",
        "print(\"Forward output:\\n\", out)\n",
        "\n",
        "\n",
        "delta_a = np.array([[10, 20], [10, 20], [10, 20]])\n",
        "dW, dB, dX = conv1d.backward(delta_a)\n",
        "print(\"Backward dB:\\n\", dB)\n",
        "print(\"Backward dW:\\n\", dW)\n",
        "print(\"Backward dX:\\n\", dX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGjnYNYH44hM",
        "outputId": "4221d20e-b86b-4c42-fcbc-f24956a13a39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward output:\n",
            " [[16. 22.]\n",
            " [17. 23.]\n",
            " [18. 24.]]\n",
            "Backward dB:\n",
            " [30 30 30]\n",
            "Backward dW:\n",
            " [[[ 50.  80. 110.]\n",
            "  [ 80. 110. 140.]]\n",
            "\n",
            " [[ 50.  80. 110.]\n",
            "  [ 80. 110. 140.]]\n",
            "\n",
            " [[ 50.  80. 110.]\n",
            "  [ 80. 110. 140.]]]\n",
            "Backward dX:\n",
            " [[30. 90. 90. 60.]\n",
            " [30. 90. 90. 60.]]\n"
          ]
        }
      ]
    }
  ]
}